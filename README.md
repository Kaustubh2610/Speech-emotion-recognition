# Speech-emotion-recognition
In order to the increase the recognition accuracy of speech emotion recognition and the characterization ability of speech, an Audio Emotion Recognition (AER) based on deep neural network is proposed. Later, research methods involving pre-processing of the data and feature extraction techniques are presented. For the utterance of speech, Mel-frequency Cepstral Coefficient is used further. Then we applied convolution Neural Network (CNN) and Long Short Term Memory (LSTM) for building our model where CNN outperformed LSTM. The following research is carried out on two files from benchmark datasets i.e. RAVDESS which includes speech and song files. Further recognition of eight emotions neutral, calm, happy, sad, angry, fearful, disgust, surprised, anger, fear, joy, can be accomplished. A remarkable accuracy of 76% was gained after evaluating the proposed model
